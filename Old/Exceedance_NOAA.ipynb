{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d018e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Merge all barrier polygons in one single shp #####\n",
    "########################################################\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas\n",
    "import geopandas\n",
    "\n",
    "folder = Path(\"E:\\Barriers\\Polygons\")\n",
    "shapefiles = folder.glob(\"*.shp\")\n",
    "gdf = pandas.concat([\n",
    "    geopandas.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(geopandas.GeoDataFrame)\n",
    "gdf.to_file(r'E:\\Barriers\\Stations\\US_barriers.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b876cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Read stations.csv and convert to geodataframe #####\n",
    "#########################################################\n",
    "\n",
    "import pandas as pd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "\n",
    "df = pd.read_csv(\"E:\\Barriers\\Stations\\Stations.csv\", sep=\",\", header=0) \n",
    "df[\"geometry\"] = df[[\"Longitude\", \"Latitude\"]].apply(Point, axis=1)\n",
    "gdf = geopandas.GeoDataFrame(df, geometry='geometry')\n",
    "gdf = gdf.set_crs(\"EPSG:4326\")\n",
    "gdf.to_file(\"E:\\Barriers\\Stations\\Stations.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf90921",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Find nearest station to each barrier and its corresponding distance #####\n",
    "###############################################################################\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "barriers= gpd.read_file(r'E:\\Barriers\\Stations\\US_barriers.shp')\n",
    "stations= gpd.read_file(r'E:\\Barriers\\Stations\\Stations.shp')\n",
    "\n",
    "barriers= barriers.to_crs('esri:102009')\n",
    "stations= stations.to_crs('esri:102009')\n",
    "\n",
    "barrier_name=[]\n",
    "min_distance=[]\n",
    "station_number=[]\n",
    "\n",
    "for i in range(0,len(barriers)):\n",
    "    name= barriers['name'][i]\n",
    "    barrier_name.append(name)\n",
    "    barrier= barriers['geometry'][i]\n",
    "    barrier= gpd.GeoSeries(barrier)\n",
    "    distance=[]\n",
    "    for j in range(0,len(stations)):\n",
    "        station= stations['geometry'][j]\n",
    "        station= gpd.GeoSeries(station)\n",
    "        dist = barrier.distance(station)\n",
    "        dist = dist.iloc[0]\n",
    "        distance.append(dist)\n",
    "        \n",
    "    min_dist= min(distance)\n",
    "    pos=[e for e, f in enumerate(distance) if f == min_dist]\n",
    "    distance_km=min_dist/1000\n",
    "    min_distance.append(distance_km)\n",
    "    station_nu=stations.Station[pos]\n",
    "    station_nu=station_nu.iloc[0]\n",
    "    station_number.append(station_nu)\n",
    "    \n",
    "df = pd.DataFrame(list(zip(barrier_name, station_number, min_distance)),\n",
    "               columns =['name', 'closest_station','distance_km'])\n",
    "df2  = barriers.merge(df, on='name', how='left')\n",
    "gdf = gpd.GeoDataFrame(df2)\n",
    "gdf.to_file(\"E:\\Barriers\\Stations\\Barriers_Stations.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Calculate exceedance probability curves #####\n",
    "###################################################\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import genextreme\n",
    "\n",
    "import requests\n",
    "import random\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load required data\n",
    "param = pd.read_csv(\"E:\\Barriers\\Stations\\Parameters.csv\", sep=\",\", header=0) # table with parameters from NOAA's report\n",
    "stations = pd.read_csv(\"E:\\Barriers\\Stations\\Stations.csv\", sep=\",\", header=0) # table with station information, including MLR trends (used to detrend historical data)\n",
    "barriers = gpd.read_file(\"E:\\Barriers\\Stations\\Barriers_Stations.shp\") # shp with Gulf and Atlantic US barriers. Code of closest station and distance to it included as attributes\n",
    "mhhw = pd.read_csv(\"E:\\Barriers\\Stations\\MHHW.csv\", sep=\",\", header=0) # table with MHHW info only for stations that were linked to the barriers\n",
    "\n",
    "\n",
    "# Loop within US barriers shp to calculate exceedance for each barrier, using parameters from the closest station\n",
    "\n",
    "for i in range(0, len(barriers)):\n",
    "    barrier= barriers['name'][i]\n",
    "    station= barriers['closest_st'][i]\n",
    "    \n",
    "    for j in range(0, len(param)):\n",
    "        if param.Station_Number[j]==station:\n",
    "            c=float(param.Shape_meters[j]) # shape parameter\n",
    "            loc=float(param.Location_meters[j])\n",
    "            scale=float(param.Scale_meters[j])\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    for k in range(0,len(stations)):\n",
    "        if stations.Station[k]==station:\n",
    "            MSL_trend=float(stations.MSL_Trend[k]) # retrieve MSL trend of that station (in mm)\n",
    "            station_name=stations.Station_Name[k]  \n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    for l in range(0,len(mhhw)):\n",
    "        if mhhw.Station[l]==station:\n",
    "            MHHW=mhhw.MHHW[l] # retrieve the local MHHW (in m)\n",
    "            print(MHHW)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    x = np.linspace(genextreme.ppf(0.001, c, loc, scale), genextreme.ppf(0.999, c, loc, scale), 100)\n",
    "  \n",
    "    ax.plot(x, genextreme.pdf(x, c, loc, scale), 'r-', lw=5, alpha=0.6, label='{0} genextreme pdf'.format(barrier, station_name))\n",
    "\n",
    "    rv = genextreme(c, loc, scale)\n",
    "    ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
    "    \n",
    "    vals = genextreme.ppf([0.001, 0.5, 0.999], c, loc, scale)\n",
    "    np.allclose([0.001, 0.5, 0.999], genextreme.cdf(vals, c, loc, scale))\n",
    "\n",
    "    r = genextreme.rvs(c, loc, scale, size=1000) # sample from the distribution to get water hts > MHHW\n",
    "    #ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    plt.title(label='{0}_{1}'.format(barrier, station_name))\n",
    "    plt.show() \n",
    "    fig.savefig(\"E:\\\\Barriers\\\\Figures\\\\Exceedance\\\\PDF\\\\{0}.png\".format(barrier), dpi=500, facecolor='w')\n",
    "    \n",
    "       \n",
    "    \n",
    "    n = len(r) # total observations\n",
    "    df = pd.DataFrame() # initialise dataframe\n",
    "    samples_sorted = list(sorted(r)) # sort 'r' observations ascending\n",
    "    rank = list(range(1, 1 + n)) # rank from 1:n, smallest first\n",
    "    df['Rank'] = rank # make 'Rank' a column of the dataframe (for easier plotting later)\n",
    "    prob = ((n - df['Rank'] + 1) / (n + 1)) # calculate probability\n",
    "    return_years = (1 / prob) # calculate return period (in years) \n",
    "    trend = [x*(MSL_trend/1000) for x in return_years] # calc linear background trend in MHW (convert MSL_trend to meters)\n",
    "    MaxWL = [x + y for x, y in zip(trend, samples_sorted)] # add trend to >MHHW samples from GEV\n",
    "    MaxWL = [x + MHHW for x in MaxWL] # for real total water level, add background MHHW level\n",
    "\n",
    "    #MaxWL = samples_sorted # for just the >MHHW heights sampled from GEV\n",
    "\n",
    "    # fill out remaining columns of dataframe (for easier plotting)\n",
    "    df['MaxWL'] = MaxWL\n",
    "    df['Probability'] = prob\n",
    "    df['Return_Pd'] = return_years\n",
    "    df.to_csv(\"E:\\Barriers\\Exceedance\\Exceedance_prob\\{0}_Exceedance.csv\".format(barrier)) # save data in csv\n",
    "    \n",
    "    #df.head(5) # check to see that the dataframe is tidy\n",
    "    # Find a specific return period & check its elevation; also shows two values nearby\n",
    "#     ret_pd = 100\n",
    "#     df.iloc[(df['Return_Pd'] - ret_pd).abs().argsort()[:3]]\n",
    "    \n",
    "    # Plot it\n",
    "    sns.set_theme()\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    \n",
    "    ax.set(xscale=\"log\")\n",
    "    ax.tick_params(left=True, bottom=True)\n",
    "    ax = sns.scatterplot(x=\"Return_Pd\", y=\"MaxWL\", data=df, color= 'r', linewidth=0, s= 25, label='exceedance probability')\n",
    "    ax.set(xlim = (0,150)) # set x axis limits\n",
    "    a =list(df.loc[df['Rank'] == 991, 'MaxWL'])[0] # to find upper limit of y axis\n",
    "    ax.set(ylim = (0, a+0.5)) # set y axis limits\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    plt.title(label='{0}_{1}'.format(barrier, station_name))\n",
    "\n",
    "    plt.savefig(\"E:\\\\Barriers\\\\Figures\\\\Exceedance\\\\Curves\\\\{0}.png\".format(barrier), dpi=500, facecolor='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
