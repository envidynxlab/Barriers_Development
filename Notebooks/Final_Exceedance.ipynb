{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ebd51f",
   "metadata": {},
   "source": [
    " # <strong>Elevation controls on road network robustness in U.S. barrier islands</strong>\n",
    " ## <strong>- Exceedance probabilities of extreme water levels for the US Atlantic and Gulf barrier islands -</strong>\n",
    " ### The purpose of this notebook is to calculate exceedance probabilities of extreme water levels in these barrier islands using a GEV approach. The parameters (scale, shape, and location) for the closest NOAA CO-OPS (Center for Operational Oceanographic Products and Services) station to each barrier island were calculated in the NOAA Technical Report NOS CO-OPS 067 (Zervas, 2013). Available in https://tidesandcurrents.noaa.gov/publications/NOAA_Technical_Report_NOS_COOPS_067a.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "151d40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import genextreme\n",
    "import requests\n",
    "import random\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82247b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set working directory\n",
    "os.chdir('E:\\\\Networks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e63eac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge all barrier polygons in one single shp \n",
    "\n",
    "# Create folder if it does no exist\n",
    "outdir= '.\\\\Data\\\\Exceedance'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "folder = Path(\".\\\\Data\\\\Barriers\\\\Barriers_AtlGulf\")\n",
    "shapefiles = folder.glob(\"*.shp\")\n",
    "gdf = pd.concat([\n",
    "    gpd.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(gpd.GeoDataFrame)\n",
    "gdf.to_file('.\\\\Data\\\\Exceedance\\\\US_barriers.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80fbe4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sofia\\AppData\\Local\\Temp/ipykernel_6128/3004197854.py:8: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(\".\\\\Data\\\\Exceedance\\\\Stations.shp\")\n"
     ]
    }
   ],
   "source": [
    "### Read stations.csv and convert to geodataframe \n",
    "\n",
    "df = pd.read_csv(\".\\\\Data\\\\Exceedance\\\\Stations.csv\", sep=\",\", header=0) \n",
    "df[\"geometry\"] = df[[\"Longitude\", \"Latitude\"]].apply(Point, axis=1)\n",
    "gdf = geopandas.GeoDataFrame(df, geometry='geometry')\n",
    "gdf = gdf.set_crs(\"EPSG:4326\")\n",
    "gdf.to_file(\".\\\\Data\\\\Exceedance\\\\Stations.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4371e4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sofia\\AppData\\Local\\Temp/ipykernel_6128/629588752.py:39: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(\".\\\\Data\\\\Exceedance\\\\Barriers_Stations.shp\")\n"
     ]
    }
   ],
   "source": [
    "### Find nearest station to each barrier and its corresponding distance \n",
    "\n",
    "barriers= gpd.read_file(r'E:\\Barriers\\Stations\\US_barriers.shp')\n",
    "stations= gpd.read_file(r'E:\\Barriers\\Stations\\Stations.shp')\n",
    "\n",
    "barriers= barriers.to_crs('esri:102009')\n",
    "stations= stations.to_crs('esri:102009')\n",
    "\n",
    "barrier_name=[]\n",
    "min_distance=[]\n",
    "station_number=[]\n",
    "\n",
    "for i in range(0,len(barriers)):\n",
    "    name= barriers['name'][i]\n",
    "    barrier_name.append(name)\n",
    "    barrier= barriers['geometry'][i]\n",
    "    barrier= gpd.GeoSeries(barrier)\n",
    "    distance=[]\n",
    "    for j in range(0,len(stations)):\n",
    "        station= stations['geometry'][j]\n",
    "        station= gpd.GeoSeries(station)\n",
    "        dist = barrier.distance(station)\n",
    "        dist = dist.iloc[0]\n",
    "        distance.append(dist)\n",
    "        \n",
    "    min_dist= min(distance)\n",
    "    pos=[e for e, f in enumerate(distance) if f == min_dist]\n",
    "    distance_km=min_dist/1000\n",
    "    min_distance.append(distance_km)\n",
    "    station_nu=stations.Station[pos]\n",
    "    station_nu=station_nu.iloc[0]\n",
    "    station_number.append(station_nu)\n",
    "    \n",
    "df = pd.DataFrame(list(zip(barrier_name, station_number, min_distance)),\n",
    "               columns =['name', 'closest_station','distance_km'])\n",
    "df2  = barriers.merge(df, on='name', how='left')\n",
    "gdf = gpd.GeoDataFrame(df2)\n",
    "gdf.to_file(\".\\\\Data\\\\Exceedance\\\\Barriers_Stations.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate exceedance probability curves \n",
    "\n",
    "    \n",
    "# Create folder if it does no exist\n",
    "outdir= '.\\\\Data\\\\Exceedance\\\\PDF'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# Create folder if it does no exist\n",
    "outdir= '.\\\\Data\\\\Exceedance\\\\Probability'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "# Create folder if it does no exist\n",
    "outdir= '.\\\\Data\\\\Exceedance\\\\Curves'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# Load required data\n",
    "param = pd.read_csv(\".\\\\Data\\\\Exceedance\\\\Parameters.csv\", sep=\",\", header=0) # table with parameters from NOAA's report\n",
    "stations = pd.read_csv(\".\\\\Data\\\\Exceedance\\\\Stations.csv\", sep=\",\", header=0) # table with station information, including MLR trends (used to detrend historical data)\n",
    "barriers = gpd.read_file(\".\\\\Data\\\\Exceedance\\\\Barriers_Stations.shp\") # shp with Gulf and Atlantic US barriers. Code of closest station and distance to it included as attributes\n",
    "mhhw = pd.read_csv(\".\\\\Data\\\\Exceedance\\\\MHHW.csv\", sep=\",\", header=0) # table with MHHW only for stations linked to the barriers islands (info extracted from https://tidesandcurrents.noaa.gov/est/)\n",
    "\n",
    "\n",
    "# Loop within US barriers shp to calculate exceedance for each barrier, using parameters from the closest station\n",
    "for i in range(0, len(barriers)):\n",
    "    barrier= barriers['name'][i]\n",
    "    station= barriers['closest_st'][i]\n",
    "    \n",
    "    for j in range(0, len(param)):\n",
    "        if param.Station_Number[j]==station:\n",
    "            c=float(param.Shape_meters[j]) # shape parameter\n",
    "            loc=float(param.Location_meters[j])\n",
    "            scale=float(param.Scale_meters[j])\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    for k in range(0,len(stations)):\n",
    "        if stations.Station[k]==station:\n",
    "            MSL_trend=float(stations.MSL_Trend[k]) # retrieve MSL trend of that station (in mm)\n",
    "            station_name=stations.Station_Name[k]  \n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    for l in range(0,len(mhhw)):\n",
    "        if mhhw.Station[l]==station:\n",
    "            MHHW=mhhw.MHHW[l] # retrieve the local MHHW (in m)\n",
    "            print(MHHW)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # plot probability distribution function\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    x = np.linspace(genextreme.ppf(0.001, c, loc, scale), genextreme.ppf(0.999, c, loc, scale), 100)\n",
    "    ax.plot(x, genextreme.pdf(x, c, loc, scale), 'r-', lw=5, alpha=0.6, label='{0} genextreme pdf'.format(barrier, station_name))\n",
    "    rv = genextreme(c, loc, scale)\n",
    "    ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
    "    \n",
    "    vals = genextreme.ppf([0.001, 0.5, 0.999], c, loc, scale)\n",
    "    np.allclose([0.001, 0.5, 0.999], genextreme.cdf(vals, c, loc, scale))\n",
    "\n",
    "    r = genextreme.rvs(c, loc, scale, size=1000) # sample from the distribution to get water hts > MHHW\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    plt.title(label='{0}_{1}'.format(barrier, station_name))\n",
    "    plt.show() \n",
    "    fig.savefig('.\\\\Data\\\\Exceedance\\\\PDF\\\\{0}.png'.format(barrier), dpi=500, facecolor='w')\n",
    "    \n",
    "       \n",
    "    # calculate exceedance probabilities and return periods\n",
    "    n = len(r) # total observations\n",
    "    df = pd.DataFrame() # initialise dataframe\n",
    "    samples_sorted = list(sorted(r)) # sort 'r' observations ascending\n",
    "    rank = list(range(1, 1 + n)) # rank from 1:n, smallest first\n",
    "    df['Rank'] = rank # make 'Rank' a column of the dataframe (for easier plotting later)\n",
    "    prob = ((n - df['Rank'] + 1) / (n + 1)) # calculate probability\n",
    "    return_years = (1 / prob) # calculate return period (in years) \n",
    "    trend = [x*(MSL_trend/1000) for x in return_years] # calc linear background trend in MHW (convert MSL_trend to meters)\n",
    "    MaxWL = [x + y for x, y in zip(trend, samples_sorted)] # add trend to >MHHW samples from GEV\n",
    "    MaxWL = [x + MHHW for x in MaxWL] # for real total water level, add background MHHW level\n",
    "\n",
    "    #MaxWL = samples_sorted # for just the >MHHW heights sampled from GEV\n",
    "\n",
    "    # fill out remaining columns of dataframe (for easier plotting)\n",
    "    df['MaxWL'] = MaxWL\n",
    "    df['Probability'] = prob\n",
    "    df['Return_Pd'] = return_years\n",
    "    df.to_csv(\".\\\\Data\\\\Exceedance\\\\Probability\\\\{0}_Exceedance.csv\".format(barrier)) # save data in csv\n",
    "    \n",
    "   \n",
    "    # plot exceedance probability curves\n",
    "    sns.set_theme()\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    \n",
    "    ax.set(xscale=\"log\")\n",
    "    ax.tick_params(left=True, bottom=True)\n",
    "    ax = sns.scatterplot(x=\"Return_Pd\", y=\"MaxWL\", data=df, color= 'r', linewidth=0, s= 25, label='exceedance probability')\n",
    "    ax.set(xlim = (0,150)) # set x axis limits\n",
    "    a =list(df.loc[df['Rank'] == 991, 'MaxWL'])[0] # to find upper limit of y axis\n",
    "    ax.set(ylim = (0, a+0.5)) # set y axis limits\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    plt.title(label='{0}_{1}'.format(barrier, station_name))\n",
    "\n",
    "    plt.savefig(\".\\\\Data\\\\Exceedance\\\\Curves\\\\{0}.png\".format(barrier), dpi=500, facecolor='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
