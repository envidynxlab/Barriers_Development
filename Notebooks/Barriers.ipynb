{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a680d6",
   "metadata": {},
   "source": [
    " # <strong>Road networks and robustness to flooding on US Atlantic and Gulf barrier islands</strong>\n",
    " ## <strong>- Download barrier island outlines for the Atlantic and Gulf coasts of the US -</strong>\n",
    " ### The purpose of this notebook is to retrieve outlines for the barrier islands located along the Atlantic and Gulf coasts of the US using the <em> Mulhern, Julia S., Johnson, Cari A., and John M. Martin 2021 Dataset for: Is barrier island morphology a function of tidal and wave regime?  The Hive: University of Utah Research Data Repository</em> https://hive.utah.edu/concern/datasets/cf95jb516?locale=en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81cde5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Packages\n",
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "import zipfile\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8e7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set working directory\n",
    "path=''\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e823073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dowload barrier island outlines from Mulhern et al., 2021\n",
    "\n",
    "# Create folder if it does no exist\n",
    "outdir= '.\\\\Data\\\\Barriers'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# Retrive zip file from repository and save it\n",
    "url = 'https://hive.utah.edu/downloads/7d278t05z'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('.\\\\Data\\\\Barriers\\\\Barriers.zip', 'wb').write(r.content)\n",
    "\n",
    "# Extract files\n",
    "with zipfile.ZipFile('.\\\\Data\\\\Barriers\\\\Barriers.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.\\\\Data\\\\Barriers\\\\')\n",
    "\n",
    "# Barrier outlines are duplicated, remove duplicated files\n",
    "my_dir = '.\\\\Data\\\\Barriers\\\\Coastal_Morph_Shapefiles_Exported_2020_06_01' \n",
    "for fname in os.listdir(my_dir):\n",
    "    if fname.endswith(\"xy_.dbf\") | fname.endswith(\"xy_.shp\") | fname.endswith(\"xy_.shx\"):\n",
    "        os.remove(os.path.join(my_dir, fname))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Downloaded polygons do not include a prj file, so crs (WGS84) needs to be defined\n",
    "\n",
    "rootdir = '.\\\\Data\\\\Barriers\\\\Coastal_Morph_Shapefiles_Exported_2020_06_01'\n",
    "extensions = ('.shp')\n",
    "\n",
    "# Iterate through folder containing the shapefiles, set crs and save shp so they have a prj file. \n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        ext = os.path.splitext(file)[-1].lower()\n",
    "        if ext in extensions:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            name= file.replace('.shp','')\n",
    "            print(name)\n",
    "            data= gpd.read_file(file_path)\n",
    "            data= data.set_crs(epsg=4326)\n",
    "            data.to_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0db0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download and import shapefile with the states of the USA\n",
    "\n",
    "# Create folder if it does no exist\n",
    "outdir= '.\\\\Data\\\\US'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# Download file and save it\n",
    "url = 'https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_state_5m.zip'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('.\\\\Data\\\\US\\\\US_States.zip', 'wb').write(r.content)\n",
    "\n",
    "# Extract files\n",
    "with zipfile.ZipFile('.\\\\Data\\\\US\\\\US_States.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.\\\\Data\\\\US\\\\')\n",
    "\n",
    "# Change crs to match the barrier outlines\n",
    "states= gpd.read_file('.\\\\Data\\\\US\\\\cb_2018_us_state_5m.shp')\n",
    "states= states.to_crs(epsg=4326)\n",
    "\n",
    "# Create subset with only the Atlantic and Gulf states\n",
    "AG= [\"Texas\", \"Lousisiana\", \"Mississipi\", \"Alabama\", \"Florida\", \"Georgia\", \"South Carolina\", \"North Carolina\", \"Virginia\", \"Maryland\", \"Delaware\", \"New Jersey\", \n",
    "          \"New York\", \"Connecticut\", \"Rhode Island\", \"Massachusetts\", \"New Hampshire\", \"Maine\"]\n",
    "\n",
    "AG_states= states[states['NAME'].isin(AtlGulf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identify which barrier islands from Mulhern et al. are located along the Atlantic and Gulf coasts of the USA\n",
    "\n",
    "# Create folder if it does no exist\n",
    "outdir= '.\\\\Data\\\\Barriers\\\\Barriers_AtlGulf'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "rootdir = '.\\\\Data\\\\Barriers\\\\Coastal_Morph_Shapefiles_Exported_2020_06_01'\n",
    "extensions = ('.shp')\n",
    "\n",
    "# Iterate through folder files and check which files intersect the AG_states shapefile\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        ext = os.path.splitext(file)[-1].lower()\n",
    "        if ext in extensions:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            name= file.replace('.shp','')\n",
    "            print(name)\n",
    "            data= gpd.read_file(file_path)\n",
    "            inp, res = AG_states.sindex.query_bulk(data.geometry, predicate='intersects')\n",
    "            data['intersects'] = np.isin(np.arange(0, len(data)), inp)\n",
    "            if data['intersects'][0]==True:\n",
    "                print (\"Intersect\")\n",
    "                data.to_file('.\\\\Data\\\\Barriers\\\\Barriers_AtlGulf\\\\{0}.shp'.format(name)) # save those barrier islands in a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7628cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL10_geo\n",
      "FL11_geo\n",
      "FL12_geo\n",
      "FL13_geo\n",
      "FL14_geo\n",
      "FL15_geo\n",
      "FL16_geo\n",
      "FL17_geo\n",
      "FL18_geo\n",
      "FL19_geo\n",
      "FL1_geo\n",
      "FL20_geo\n",
      "FL21_geo\n",
      "FL23_geo\n",
      "FL24_geo\n",
      "FL25_geo\n",
      "FL26_geo\n",
      "FL27_geo\n",
      "FL28_geo\n",
      "FL29_geo\n",
      "FL2_geo\n",
      "FL30_geo\n",
      "FL31_geo\n",
      "FL32_geo\n",
      "FL33_geo\n",
      "FL34_geo\n",
      "FL35_geo\n",
      "FL36_geo\n",
      "FL37_geo\n",
      "FL38_geo\n",
      "FL39_geo\n",
      "FL3_geo\n",
      "FL4_geo\n",
      "FL5_geo\n",
      "FL6_geo\n",
      "FL7_geo\n",
      "FL8_geo\n",
      "FL9_geo\n",
      "GA10_geo\n",
      "GA1_geo\n",
      "GA2_geo\n",
      "GA3_geo\n",
      "GA4_geo\n",
      "GA5_geo\n",
      "GA6_geo\n",
      "GA7_geo\n",
      "GA8_geo\n",
      "GA9_geo\n",
      "LA3_geo\n",
      "LA4_geo\n",
      "LA5_geo\n",
      "LA6_geo\n",
      "LA7_geo\n",
      "LA8_geo\n",
      "MA10_geo\n",
      "MA11_geo\n",
      "MA12_geo\n",
      "MA13_geo\n",
      "MA14_geo\n",
      "MA1_geo\n",
      "MA2_geo\n",
      "MA3_geo\n",
      "MA4_geo\n",
      "MA5_geo\n",
      "MA6_geo\n",
      "MA7_geo\n",
      "MA8_geo\n",
      "MA9_geo\n",
      "NC10_geo\n",
      "NC11_geo\n",
      "NC12_geo\n",
      "NC13_geo\n",
      "NC14_geo\n",
      "NC15_geo\n",
      "NC16_geo\n",
      "NC17_geo\n",
      "NC18_geo\n",
      "NC19_geo\n",
      "NC1_geo\n",
      "NC20_geo\n",
      "NC21_geo\n",
      "NC22_geo\n",
      "NC2_geo\n",
      "NC3_geo\n",
      "NC4_geo\n",
      "NC5_geo\n",
      "NC6_geo\n",
      "NC7_geo\n",
      "NC8_geo\n",
      "NC9_geo\n",
      "NJ10_geo\n",
      "NJ11_geo\n",
      "NJ1_geo\n",
      "NJ2_geo\n",
      "NJ3_geo\n",
      "NJ4_geo\n",
      "NJ5_geo\n",
      "NJ6_geo\n",
      "NJ7_geo\n",
      "NJ8_geo\n",
      "NJ9_geo\n",
      "NY1_geo\n",
      "NY2_geo\n",
      "NY3_geo\n",
      "NY4_geo\n",
      "NY5_geo\n",
      "NY6_geo\n",
      "NY7_geo\n",
      "RI1_geo\n",
      "RI2_geo\n",
      "RI3_geo\n",
      "RI4_geo\n",
      "RI5_geo\n",
      "SC10_geo\n",
      "SC11_geo\n",
      "SC12_geo\n",
      "SC13_geo\n",
      "SC14_geo\n",
      "SC15_geo\n",
      "SC16_geo\n",
      "SC17_geo\n",
      "SC18_geo\n",
      "SC19_geo\n",
      "SC1_geo\n",
      "SC20_geo\n",
      "SC21_geo\n",
      "SC22_geo\n",
      "SC23_geo\n",
      "SC24_geo\n",
      "SC25_geo\n",
      "SC26_geo\n",
      "SC2_geo\n",
      "SC3_geo\n",
      "SC4_geo\n",
      "SC5_geo\n",
      "SC6_geo\n",
      "SC7_geo\n",
      "SC8_geo\n",
      "SC9_geo\n",
      "TX10_geo\n",
      "TX11_geo\n",
      "TX12_geo\n",
      "TX1_geo\n",
      "TX2_geo\n",
      "TX3_geo\n",
      "TX4_geo\n",
      "TX5_geo\n",
      "TX6_geo\n",
      "TX7_geo\n",
      "TX8_geo\n",
      "TX9_geo\n",
      "VA10_geo\n",
      "VA11_geo\n",
      "VA12_geo\n",
      "VA13_geo\n",
      "VA14_geo\n",
      "VA15_geo\n",
      "VA1_geo\n",
      "VA2_geo\n",
      "VA3_geo\n",
      "VA4_geo\n",
      "VA5_geo\n",
      "VA6_geo\n",
      "VA7_geo\n",
      "VA8_geo\n",
      "VA9_geo\n"
     ]
    }
   ],
   "source": [
    "### Create 200 m buffer around barrier outlines to clip CUDEM tiles and make sure that all network nodes (when downloaded) have elevation data\n",
    "\n",
    "# Loop within polygons folder and create a 200m buffer to increase the size of each barrier.  \n",
    "rootdir = '.\\\\Data\\\\Barriers\\\\Barriers_AtlGulf'\n",
    "extensions = ('.shp')\n",
    "outdir = '.\\\\Data\\\\Barriers\\\\Buffers_200m'\n",
    "\n",
    "# Create folder if it does no exist\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        ext = os.path.splitext(file)[-1].lower()\n",
    "        if ext in extensions:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            name= file.replace('.shp','')\n",
    "            print(name)\n",
    "            # Read polygons\n",
    "            barrier = gpd.read_file(file_path)\n",
    "            # Change crs to projected\n",
    "            barrier = barrier.to_crs('esri:102003')\n",
    "            # Buffer 100m\n",
    "            barrier2 = barrier['geometry'] = barrier.geometry.buffer(200)\n",
    "            # Reproject to original crs\n",
    "            barrier2= barrier2.to_crs(epsg=4326)\n",
    "            # Save file\n",
    "            barrier2.to_file('.\\\\Data\\\\Barriers\\\\Buffers_200m\\\\{0}.shp'.format(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
