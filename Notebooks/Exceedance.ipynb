{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35c243d",
   "metadata": {},
   "source": [
    " # <strong>Road networks and robustness to flooding on US Atlantic and Gulf barrier islands</strong>\n",
    " ## <strong>- Calculate exceedance probabilities of extreme water levels for the US Atlantic and Gulf barrier islands -</strong>\n",
    " ### The purpose of this notebook is to calculate exceedance probabilities of extreme water levels in these barrier islands using a GEV approach. The parameters (scale, shape, and location) for the closest NOAA CO-OPS (Center for Operational Oceanographic Products and Services) station to each barrier island were extracted from the NOAA Technical Report NOS CO-OPS 067 (Zervas, 2013) available in https://tidesandcurrents.noaa.gov/publications/NOAA_Technical_Report_NOS_COOPS_067a.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207e9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Packages\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import genextreme\n",
    "import requests\n",
    "import random\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29cb4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set working directory\n",
    "\n",
    "path='' # introduce path to your working directory\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3b99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge all barrier polygons in one single shp \n",
    "\n",
    "# Create folder if it does no exist\n",
    "outdir= './Data/Exceedance'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "# Read all barrier shp and merge them in one single dataset\n",
    "folder = Path(\"./Data/Barriers/Barriers_AtlGulf\")\n",
    "shapefiles = folder.glob(\"*.shp\")\n",
    "gdf = pd.concat([\n",
    "    gpd.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(gpd.GeoDataFrame)\n",
    "\n",
    "# For some barrier islands, the column \"name\" has a different format. Convert name to same format so they can be matched later\n",
    "gdf.loc[gdf.name == 'Fl14', 'name'] = 'FL14'\n",
    "gdf.loc[gdf.name == 'NC1   -           Core        Banks', 'name'] = 'NC1'\n",
    "gdf.loc[gdf.name == 'NC2-        Cape     Lookout, NC', 'name'] = 'NC2'\n",
    "gdf.loc[gdf.name == 'NC3  ShacklefordBanks,     NC', 'name'] = 'NC3'\n",
    "gdf.loc[gdf.name == 'NC4-        Bogue    Banks,   NC', 'name'] = 'NC4'\n",
    "gdf.loc[gdf.name == 'NC12Ocracoke  Island,   NC', 'name'] = 'NC12'\n",
    "gdf.loc[gdf.name == 'VA1    -            Smith        Island', 'name'] = 'VA1'\n",
    "gdf.loc[gdf.name == 'VA2    -            Wreck        Island', 'name'] = 'VA2'\n",
    "gdf.loc[gdf.name == 'VA3 -         AssateagueIsland,   MD', 'name'] = 'VA3'\n",
    "\n",
    "gdf.to_file('./Data/Exceedance/US_barriers.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ffb8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read stations.csv and convert to geodataframe \n",
    "\n",
    "df = pd.read_csv(\"./Data/Stations.csv\", sep=\",\", header=0) \n",
    "df[\"geometry\"] = df[[\"Longitude\", \"Latitude\"]].apply(Point, axis=1)\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "gdf = gdf.set_crs(\"EPSG:4326\")\n",
    "gdf.to_file(\"./Data/Exceedance/Stations.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3013334",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find nearest station to each barrier and its corresponding distance \n",
    "\n",
    "barriers= gpd.read_file('./Data/Exceedance/US_barriers.shp')\n",
    "stations= gpd.read_file('./Data/Exceedance/Stations.shp')\n",
    "\n",
    "barriers= barriers.to_crs('esri:102009')\n",
    "stations= stations.to_crs('esri:102009')\n",
    "\n",
    "barrier_name=[]\n",
    "min_distance=[]\n",
    "station_number=[]\n",
    "\n",
    "for i in range(0,len(barriers)):\n",
    "    name= barriers['name'][i]\n",
    "    barrier_name.append(name)\n",
    "    barrier= barriers['geometry'][i]\n",
    "    barrier= gpd.GeoSeries(barrier)\n",
    "    distance=[]\n",
    "    for j in range(0,len(stations)):\n",
    "        station= stations['geometry'][j]\n",
    "        station= gpd.GeoSeries(station)\n",
    "        dist = barrier.distance(station)\n",
    "        dist = dist.iloc[0]\n",
    "        distance.append(dist)\n",
    "        \n",
    "    min_dist= min(distance)\n",
    "    pos=[e for e, f in enumerate(distance) if f == min_dist]\n",
    "    distance_km=min_dist/1000\n",
    "    min_distance.append(distance_km)\n",
    "    station_nu=stations.Station[pos]\n",
    "    station_nu=station_nu.iloc[0]\n",
    "    station_number.append(station_nu)\n",
    "    \n",
    "df = pd.DataFrame(list(zip(barrier_name, station_number, min_distance)),\n",
    "               columns =['name', 'closest_station','distance_km'])\n",
    "df2  = barriers.merge(df, on='name', how='left')\n",
    "gdf = gpd.GeoDataFrame(df2)\n",
    "gdf.to_file(\"./Data/Exceedance/Barriers_Stations.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec74087",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate exceedance probability curves \n",
    "\n",
    "# Create folder if it does no exist\n",
    "outdir= './Data/Exceedance/PDF'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# Create folder if it does no exist\n",
    "outdir= './Data/Exceedance/Probability'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "# Create folder if it does no exist\n",
    "outdir= './Data/Exceedance/Curves'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# Load required data (.csv file available in GitHub, see \"Data\" folder)\n",
    "param = pd.read_csv(\"./Data/Parameters.csv\", sep=\",\", header=0) # table with parameters from NOAA's report \n",
    "stations = pd.read_csv(\"./Data/Stations.csv\", sep=\",\", header=0) # table with station information, including MLR trends (used to detrend historical data)\n",
    "mhhw = pd.read_csv(\"./Data/MHHW.csv\", sep=\",\", header=0) # table with MHHW only for stations linked to the barriers islands (info extracted from https://tidesandcurrents.noaa.gov/est/)\n",
    "barriers = gpd.read_file(\"./Data/Exceedance/Barriers_Stations.shp\") # shp with Gulf and Atlantic US barriers. Code of closest station and distance to it included as attributes\n",
    "\n",
    "\n",
    "# Loop within US barriers shp to calculate exceedance for each barrier, using parameters from the closest station\n",
    "for i in range(0, len(barriers)):\n",
    "    barrier= barriers['name'][i]\n",
    "    station= barriers['closest_st'][i]\n",
    "    \n",
    "    for j in range(0, len(param)):\n",
    "        if param.Station_Number[j]==station:\n",
    "            c=float(param.Shape_meters[j]) # shape parameter\n",
    "            loc=float(param.Location_meters[j]) # location parameter\n",
    "            scale=float(param.Scale_meters[j]) # scale parameter\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    for k in range(0,len(stations)):\n",
    "        if stations.Station[k]==station:\n",
    "            MSL_trend=float(stations.MSL_Trend[k]) # retrieve MSL trend of that station (in mm)\n",
    "            station_name=stations.Station_Name[k]  \n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    for l in range(0,len(mhhw)):\n",
    "        if mhhw.Station[l]==station:\n",
    "            MHHW=mhhw.MHHW[l] # retrieve the local MHHW (in m)\n",
    "            print(MHHW)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # plot probability distribution function\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    x = np.linspace(genextreme.ppf(0.001, c, loc, scale), genextreme.ppf(0.999, c, loc, scale), 100)\n",
    "    ax.plot(x, genextreme.pdf(x, c, loc, scale), 'r-', lw=5, alpha=0.6, label='{0} genextreme pdf'.format(barrier, station_name))\n",
    "    rv = genextreme(c, loc, scale)\n",
    "    ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
    "    \n",
    "    vals = genextreme.ppf([0.001, 0.5, 0.999], c, loc, scale)\n",
    "    np.allclose([0.001, 0.5, 0.999], genextreme.cdf(vals, c, loc, scale))\n",
    "\n",
    "    r = genextreme.rvs(c, loc, scale, size=1000) # sample from the distribution to get water hts > MHHW\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    plt.title(label='{0}_{1}'.format(barrier, station_name))\n",
    "    plt.show() \n",
    "    fig.savefig('./Data/Exceedance/PDF/{0}.png'.format(barrier), dpi=500, facecolor='w')\n",
    "    plt.close(\"all\")\n",
    "       \n",
    "    # calculate exceedance probabilities and return periods\n",
    "    n = len(r) # total observations\n",
    "    df = pd.DataFrame() # initialise dataframe\n",
    "    samples_sorted = list(sorted(r)) # sort 'r' observations ascending\n",
    "    rank = list(range(1, 1 + n)) # rank from 1:n, smallest first\n",
    "    df['Rank'] = rank # make 'Rank' a column of the dataframe (for easier plotting later)\n",
    "    prob = ((n - df['Rank'] + 1) / (n + 1)) # calculate probability\n",
    "    return_years = (1 / prob) # calculate return period (in years) \n",
    "    trend = [x*(MSL_trend/1000) for x in return_years] # calculate linear background trend in MHW (convert MSL_trend to meters)\n",
    "    MaxWL = [x + y for x, y in zip(trend, samples_sorted)] # add trend to >MHHW samples from GEV\n",
    "    MaxWL = [x + MHHW for x in MaxWL] # for real total water level, add background MHHW level\n",
    "\n",
    "    # fill out remaining columns of dataframe (for easier plotting)\n",
    "    df['MaxWL'] = MaxWL\n",
    "    df['Probability'] = prob\n",
    "    df['Return_Pd'] = return_years\n",
    "    df.to_csv(\"./Data/Exceedance/Probability/{0}_Exceedance.csv\".format(barrier)) # save data in csv\n",
    "    \n",
    "    # plot exceedance probability curves\n",
    "    sns.set_theme()\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    \n",
    "    ax.set(xscale=\"log\")\n",
    "    ax.tick_params(left=True, bottom=True)\n",
    "    ax = sns.scatterplot(x=\"Return_Pd\", y=\"MaxWL\", data=df, color= 'r', linewidth=0, s= 25, label='exceedance probability')\n",
    "    ax.set(xlim = (0,150)) # set x axis limits\n",
    "    a =list(df.loc[df['Rank'] == 991, 'MaxWL'])[0] # to find upper limit of y axis\n",
    "    ax.set(ylim = (0, a+0.5)) # set y axis limits\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    plt.title(label='{0}_{1}'.format(barrier, station_name))\n",
    "    plt.savefig(\"./Data/Exceedance/Curves/{0}.png\".format(barrier), dpi=500, facecolor='w')\n",
    "    plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
